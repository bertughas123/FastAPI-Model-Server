"""
Gemini API ile Performans Analizi Servisi
Redis TabanlÄ± Cache ve Rate Limiting

Ã–zellikler:
- Cache-First Pattern: Ã–nce Redis cache kontrol edilir
- Global Rate Limiting: TÃ¼m worker'lar aynÄ± sayacÄ± paylaÅŸÄ±r
- Fallback: API hatalarÄ±nda kural tabanlÄ± analiz
- Lazy Initialization: Redis servisleri ilk Ã§aÄŸrÄ±da baÅŸlatÄ±lÄ±r
"""
import google.generativeai as genai
from typing import Optional
import os
from dotenv import load_dotenv

from schemas.metrics import (
    AggregatedMetrics,
    GeminiAnalysisReport,
    PerformanceIssue,
)
from database.redis_connection import RedisManager
from core.redis_rate_limiter import RedisRateLimiter
from services.redis_cache import RedisCacheService

load_dotenv()


class GeminiAnalyzerRedis:
    """
    Gemini API kullanarak metrik analizi yapan sÄ±nÄ±f
    
    Redis Entegrasyonu:
    - Cache: AynÄ± metrikler iÃ§in tekrar API Ã§aÄŸrÄ±sÄ± yapma
    - Rate Limit: Global API kota korumasÄ± (Sliding Window)
    
    AkÄ±ÅŸ:
    1. Cache kontrolÃ¼ (HIT â†’ direkt dÃ¶ndÃ¼r, rate limit artmaz)
    2. Rate limit kontrolÃ¼ (MISS â†’ limit check)
    3. API isteÄŸi
    4. Cache'e kaydet
    """
    
    # Class-level services (singleton pattern)
    _rate_limiter: Optional[RedisRateLimiter] = None
    _cache_service: Optional[RedisCacheService] = None
    
    def __init__(self):
        """API key ile Gemini'yi yapÄ±landÄ±r"""
        api_key = os.getenv("GEMINI_API_KEY")
        
        if not api_key or api_key == "your_api_key_here":
            print("âš ï¸  GEMINI_API_KEY bulunamadÄ±! .env dosyasÄ±nÄ± kontrol edin.")
            print("   API key almak iÃ§in: https://aistudio.google.com/app/apikey")
            self.model = None
            return
        
        # Gemini yapÄ±landÄ±rmasÄ±
        genai.configure(api_key=api_key)
        
        # Model konfigÃ¼rasyonu (.env'den okunur)
        self.model_name = os.getenv("GEMINI_MODEL", "gemini-2.5-flash-lite")
        self.temperature = float(os.getenv("GEMINI_TEMPERATURE", "0.3"))
        self.max_tokens = int(os.getenv("GEMINI_MAX_TOKENS", "1024"))
        
        # Model instance (Native JSON Mode - 0.4.0+ gerektirir)
        self.model = genai.GenerativeModel(
            model_name=self.model_name,
            generation_config={
                "temperature": self.temperature,
                "max_output_tokens": self.max_tokens,
                "response_mime_type": "application/json",  # Native JSON mode
            }
        )
        
        # Rate Limit ayarlarÄ±
        self.rate_limit_max = int(os.getenv("GEMINI_RATE_LIMIT", "10"))
        self.rate_limit_window = 60  # 1 dakika (Sliding Window)
        
        # Cache ayarlarÄ±
        self.cache_ttl = int(os.getenv("GEMINI_CACHE_TTL", "300"))  # 5 dakika
        
        print(f"âœ… Gemini Analyzer (Redis) hazÄ±r")
        print(f"   Model: {self.model_name}")
        print(f"   Rate Limit: {self.rate_limit_max} req/min (Global)")
        print(f"   Cache TTL: {self.cache_ttl}s")
    
    def _ensure_services(self) -> None:
        """
        Redis servislerinin baÅŸlatÄ±ldÄ±ÄŸÄ±ndan emin ol (Lazy Initialization)
        
        Neden lazy?
        - __init__ sÄ±rasÄ±nda Redis baÄŸlantÄ±sÄ± olmayabilir
        - Servisleri sadece gerÃ§ekten ihtiyaÃ§ duyulduÄŸunda baÅŸlat
        - Singleton pattern ile tekrar yaratmayÄ± Ã¶nle
        """
        if GeminiAnalyzerRedis._rate_limiter is None:
            redis_client = RedisManager.get_client()
            
            # Global rate limiter (tÃ¼m worker'lar paylaÅŸÄ±r)
            GeminiAnalyzerRedis._rate_limiter = RedisRateLimiter(
                redis_client=redis_client,
                key_prefix="gemini_ratelimit",
                max_requests=self.rate_limit_max,
                window_seconds=self.rate_limit_window
            )
            
            # Cache servisi
            GeminiAnalyzerRedis._cache_service = RedisCacheService(
                redis_client=redis_client,
                key_prefix="gemini_cache",
                default_ttl=self.cache_ttl
            )
            
            print("   ğŸ”„ Redis servisleri baÅŸlatÄ±ldÄ± (lazy init)")
    
    def _generate_cache_key(
        self,
        current: AggregatedMetrics,
        previous: Optional[AggregatedMetrics]
    ) -> str:
        """
        Metrikler iÃ§in deterministic cache key oluÅŸtur
        
        AynÄ± metrikler â†’ AynÄ± key â†’ Cache HIT
        
        Hassasiyet:
        - confidence: 2 ondalÄ±k
        - latency: 1 ondalÄ±k
        - time: dakika hassasiyeti
        """
        return RedisCacheService.generate_hash_key(
            total=current.total_predictions,
            confidence=round(current.average_confidence, 2),
            latency=round(current.average_inference_time_ms, 1),
            time=current.time_window_end.isoformat()[:16],  # Dakika hassasiyeti
            prev_total=previous.total_predictions if previous else 0
        )
    
    async def analyze_performance(
        self,
        current_metrics: AggregatedMetrics,
        previous_metrics: Optional[AggregatedMetrics] = None
    ) -> GeminiAnalysisReport:
        """
        Performans metriklerini Gemini ile analiz et
        
        Args:
            current_metrics: GÃ¼ncel metrikler
            previous_metrics: KarÅŸÄ±laÅŸtÄ±rma iÃ§in Ã¶nceki metrikler (opsiyonel)
            
        Returns:
            GeminiAnalysisReport: Analiz raporu
        
        AkÄ±ÅŸ:
        1. Cache kontrolÃ¼ (HIT â†’ direkt dÃ¶ndÃ¼r, rate limit artmaz)
        2. Rate limit kontrolÃ¼ (MISS â†’ limit check)
        3. API isteÄŸi
        4. Cache'e kaydet
        """
        if not self.model:
            return self._create_fallback_report(
                current_metrics,
                "Gemini API key yapÄ±landÄ±rÄ±lmamÄ±ÅŸ"
            )
        
        # Redis servislerini baÅŸlat (lazy)
        self._ensure_services()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ADIM 1: CACHE KONTROLÃœ
        # Cache HIT â†’ Rate limit artmaz, direkt dÃ¶ndÃ¼r
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        cache_key = self._generate_cache_key(current_metrics, previous_metrics)
        
        cached_report = await GeminiAnalyzerRedis._cache_service.get(
            cache_key,
            GeminiAnalysisReport
        )
        
        if cached_report:
            print(f"ğŸ“¦ Cache HIT: {cache_key[:8]}...")
            # Metrikleri gÃ¼ncelle (cache'te None olabilir)
            cached_report.metrics_analyzed = current_metrics
            return cached_report
        
        print(f"ğŸ“­ Cache MISS: {cache_key[:8]}...")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ADIM 2: RATE LIMIT KONTROLÃœ (Sadece cache miss'te)
        # Bu sayede 100 istek gelse bile sadece 1 API Ã§aÄŸrÄ±sÄ± yapÄ±lÄ±r
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        allowed, remaining = await GeminiAnalyzerRedis._rate_limiter.is_allowed("global")
        
        if not allowed:
            reset_time = await GeminiAnalyzerRedis._rate_limiter.get_reset_time("global")
            return self._create_fallback_report(
                current_metrics,
                f"Global rate limit aÅŸÄ±ldÄ± ({self.rate_limit_max}/dk). "
                f"Yeniden deneme: {reset_time} saniye"
            )
        
        print(f"ğŸš¦ Rate limit OK. Kalan: {remaining}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ADIM 3: API Ä°STEÄÄ°
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        try:
            prompt = self._build_analysis_prompt(current_metrics, previous_metrics)
            
            # Gemini API Ã§aÄŸrÄ±sÄ± (sync - google.generativeai sync'tir)
            response = self.model.generate_content(prompt)
            report = self._parse_gemini_response(response.text, current_metrics)
            
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ Gemini API hatasÄ±: {error_msg}")
            return self._create_fallback_report(current_metrics, error_msg)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ADIM 4: CACHE'E KAYDET
        # Bir sonraki aynÄ± istek iÃ§in hazÄ±r
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        await GeminiAnalyzerRedis._cache_service.set(
            cache_key,
            report,
            ttl=self.cache_ttl
        )
        print(f"ğŸ’¾ Cache kaydedildi: {cache_key[:8]}... (TTL: {self.cache_ttl}s)")
        
        return report
    
    def _build_analysis_prompt(
        self,
        current: AggregatedMetrics,
        previous: Optional[AggregatedMetrics]
    ) -> str:
        """Gemini iÃ§in detaylÄ± analiz prompt'u oluÅŸtur"""
        
        prompt = f"""Sen bir Machine Learning Model Performance Analyst'sÄ±n.
Bir sentiment analiz modelinin performans metriklerini analiz etmelisin.

## GÃœNCEL METRÄ°KLER ({current.time_window_start} - {current.time_window_end})
- Toplam Tahmin SayÄ±sÄ±: {current.total_predictions}
- Ortalama GÃ¼ven Skoru: {current.average_confidence:.2f}
- Ortalama Gecikme: {current.average_inference_time_ms:.2f}ms
- P95 Gecikme: {current.p95_inference_time_ms:.2f}ms
- Min/Max Gecikme: {current.min_inference_time_ms:.2f}ms / {current.max_inference_time_ms:.2f}ms
- Sentiment DaÄŸÄ±lÄ±mÄ±: {dict(current.sentiment_distribution)}
- Durum: {current.status.value}
"""
        
        # Ã–nceki metriklerle karÅŸÄ±laÅŸtÄ±rma
        if previous and previous.total_predictions > 0:
            conf_change = ((current.average_confidence - previous.average_confidence) 
                          / previous.average_confidence * 100)
            
            # P95 Gecikme DeÄŸiÅŸimi (tail latency analizi iÃ§in daha profesyonel)
            # Fallback: p95 deÄŸeri None veya 0 ise hesaplama yapma
            if (previous.p95_inference_time_ms and previous.p95_inference_time_ms > 0 and
                current.p95_inference_time_ms and current.p95_inference_time_ms > 0):
                p95_latency_change = ((current.p95_inference_time_ms - previous.p95_inference_time_ms)
                                     / previous.p95_inference_time_ms * 100)
                p95_change_text = f"{p95_latency_change:+.1f}%"
            else:
                p95_change_text = "HesaplanamadÄ± (yetersiz veri)"
            
            prompt += f"""
## Ã–NCEKÄ° DÃ–NEM Ä°LE KARÅILAÅTIRMA
- GÃ¼ven Skoru DeÄŸiÅŸimi: {conf_change:+.1f}%
- P95 Gecikme DeÄŸiÅŸimi: {p95_change_text}
- Tahmin SayÄ±sÄ± FarkÄ±: {current.total_predictions - previous.total_predictions:+d}
"""
        
        prompt += """
## GÃ–REV
AÅŸaÄŸÄ±daki JSON formatÄ±nda bir analiz raporu oluÅŸtur:

```json
{
  "summary": "2-3 cÃ¼mlelik Ã¶zet",
  "identified_issues": [
    {
      "issue_type": "low_confidence | high_latency | data_drift",
      "severity": "low | medium | high | critical",
      "description": "Sorun aÃ§Ä±klamasÄ±"
    }
  ],
  "recommendations": [
    "Ã–neri 1",
    "Ã–neri 2"
  ],
  "root_cause_hypothesis": "KÃ¶k neden hakkÄ±nda hipotez",
  "confidence_score": 0.0-1.0 (bu analizine ne kadar gÃ¼veniyorsun)
}
```

Ã–NEMLÄ°:
- YanÄ±tÄ±nÄ± SADECE JSON olarak ver, baÅŸka metin ekleme
- identified_issues boÅŸ liste olabilir (sorun yoksa)
- TÃ¼rkÃ§e yaz
- Somut, actionable Ã¶neriler ver
- EÄŸer metrik sayÄ±sÄ± Ã§ok azsa (< 5), bunu belirt
"""
        
        return prompt
    
    def _parse_gemini_response(
        self,
        response_text: str,
        metrics: AggregatedMetrics
    ) -> GeminiAnalysisReport:
        """
        Gemini'nin JSON yanÄ±tÄ±nÄ± Pydantic ile parse et (Native JSON Mode)
        
        response_mime_type="application/json" sayesinde Gemini doÄŸrudan
        JSON dÃ¶ner, manuel string parsing'e gerek yok.
        """
        try:
            # Pydantic native JSON validation
            report = GeminiAnalysisReport.model_validate_json(response_text)
            
            # Metrik bilgisini manuel olarak ekle (Gemini bunu bilmiyor)
            report.metrics_analyzed = metrics
            
            return report
            
        except Exception as e:
            print(f"âš ï¸ Gemini yanÄ±tÄ± parse edilemedi: {e}")
            print(f"YanÄ±t: {response_text[:200]}...")
            return self._create_fallback_report(metrics, f"Parse hatasÄ±: {str(e)}")
    
    def _create_fallback_report(
        self,
        metrics: AggregatedMetrics,
        error_msg: str
    ) -> GeminiAnalysisReport:
        """
        Hata durumunda kural tabanlÄ± varsayÄ±lan rapor oluÅŸtur
        
        Tetiklenme durumlarÄ±:
        - Rate limit aÅŸÄ±ldÄ±
        - API hatasÄ±
        - Parse hatasÄ±
        - API key yok
        """
        issues = []
        recommendations = []
        
        # DÃ¼ÅŸÃ¼k gÃ¼ven kontrolÃ¼
        if metrics.average_confidence < 0.6:
            issues.append(PerformanceIssue(
                issue_type="low_confidence",
                severity="high",
                description=f"Ortalama gÃ¼ven skoru dÃ¼ÅŸÃ¼k: {metrics.average_confidence:.2f}"
            ))
            recommendations.append("Model yeniden eÄŸitimi dÃ¼ÅŸÃ¼nÃ¼n")
        
        # YÃ¼ksek gecikme kontrolÃ¼
        if metrics.average_inference_time_ms > 200:
            issues.append(PerformanceIssue(
                issue_type="high_latency",
                severity="medium",
                description=f"Ortalama gecikme yÃ¼ksek: {metrics.average_inference_time_ms:.2f}ms"
            ))
            recommendations.append("Sunucu kaynaklarÄ±nÄ± kontrol edin")
        
        # Yetersiz veri kontrolÃ¼
        if metrics.total_predictions < 5:
            summary = f"Yetersiz veri: Sadece {metrics.total_predictions} tahmin var. Daha fazla veri toplanmalÄ±."
        else:
            summary = f"Otomatik analiz: {len(issues)} sorun tespit edildi. (Hata: {error_msg})"
        
        return GeminiAnalysisReport(
            summary=summary,
            identified_issues=issues,
            recommendations=recommendations if recommendations else ["Daha fazla veri toplayÄ±n"],
            root_cause_hypothesis="Gemini API kullanÄ±lamadÄ±ÄŸÄ± iÃ§in kural tabanlÄ± analiz yapÄ±ldÄ±",
            confidence_score=0.3,
            metrics_analyzed=metrics
        )
    
    async def get_cache_stats(self) -> dict:
        """Cache istatistiklerini dÃ¶ndÃ¼r (debug/monitoring iÃ§in)"""
        self._ensure_services()
        return await GeminiAnalyzerRedis._cache_service.get_stats()
    
    async def get_rate_limit_status(self, identifier: str = "global") -> dict:
        """Rate limit durumunu dÃ¶ndÃ¼r"""
        self._ensure_services()
        _, remaining = await GeminiAnalyzerRedis._rate_limiter.is_allowed(identifier)
        reset_time = await GeminiAnalyzerRedis._rate_limiter.get_reset_time(identifier)
        
        return {
            "identifier": identifier,
            "remaining": remaining + 1,  # is_allowed bir hak kullandÄ±, geri ekle
            "max_requests": self.rate_limit_max,
            "reset_in_seconds": reset_time,
            "window_seconds": self.rate_limit_window
        }
    
    async def invalidate_cache(self, pattern: str = "*") -> int:
        """Cache'i temizle (threshold deÄŸiÅŸikliÄŸinde kullanÄ±lÄ±r)"""
        self._ensure_services()
        deleted = await GeminiAnalyzerRedis._cache_service.clear_prefix(pattern)
        print(f"ğŸ—‘ï¸ {deleted} cache entry silindi")
        return deleted


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BACKWARD COMPATIBILITY
# Eski kod `gemini_analyzer` kullanÄ±yorsa Ã§alÄ±ÅŸmaya devam etsin
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Global instance (yeni sÄ±nÄ±f)
gemini_analyzer = GeminiAnalyzerRedis()

# Legacy alias (eski import'lar iÃ§in)
GeminiAnalyzer = GeminiAnalyzerRedis
