"""
Gemini API ile Performans Analizi Servisi
Redis TabanlÄ± Cache ve Rate Limiting + Tenacity Resilience

Ã–zellikler:
- Cache-First Pattern: Ã–nce Redis cache kontrol edilir
- Global Rate Limiting: TÃ¼m worker'lar aynÄ± sayacÄ± paylaÅŸÄ±r
- Fallback: API hatalarÄ±nda kural tabanlÄ± analiz
- Lazy Initialization: Redis servisleri ilk Ã§aÄŸrÄ±da baÅŸlatÄ±lÄ±r
- Retry Mechanism: GeÃ§ici hatalarda Exponential Backoff ile yeniden deneme
"""
import google.generativeai as genai
from typing import Optional
import os
from dotenv import load_dotenv

# Tenacity - Retry mekanizmasÄ±
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    wait_random,
    retry_if_exception_type,
    RetryError
)

# Google API hatalarÄ±
from google.api_core.exceptions import (
    ServiceUnavailable,      # 503 - GeÃ§ici, retry mantÄ±klÄ±
    DeadlineExceeded,        # Timeout - GeÃ§ici, retry mantÄ±klÄ±
    InternalServerError,     # 500 - Bazen geÃ§ici
    ResourceExhausted,       # 429 - Rate limit (retry YAPMA!)
)

from schemas.metrics import (
    AggregatedMetrics,
    GeminiAnalysisReport,
    PerformanceIssue,
)
from database.redis_connection import RedisManager
from core.redis_rate_limiter import RedisRateLimiter
from services.redis_cache import RedisCacheService

load_dotenv()


class GeminiAnalyzerRedis:
    """
    Gemini API kullanarak metrik analizi yapan sÄ±nÄ±f
    
    Redis Entegrasyonu:
    - Cache: AynÄ± metrikler iÃ§in tekrar API Ã§aÄŸrÄ±sÄ± yapma
    - Rate Limit: Global API kota korumasÄ± (Sliding Window)
    
    Resilience (Tenacity):
    - GeÃ§ici hatalarda (503, 500, Timeout) 4 deneme
    - Exponential Backoff + Jitter
    - 429 (ResourceExhausted) retry YAPILMAZ
    
    AkÄ±ÅŸ:
    1. Cache kontrolÃ¼ (HIT â†’ direkt dÃ¶ndÃ¼r, rate limit artmaz)
    2. Rate limit kontrolÃ¼ (MISS â†’ limit check)
    3. API isteÄŸi (Retry korumalÄ±)
    4. Cache'e kaydet
    """
    
    # Class-level services (singleton pattern)
    _rate_limiter: Optional[RedisRateLimiter] = None
    _cache_service: Optional[RedisCacheService] = None
    
    def __init__(self):
        """API key ile Gemini'yi yapÄ±landÄ±r"""
        api_key = os.getenv("GEMINI_API_KEY")
        
        if not api_key or api_key == "your_api_key_here":
            print("âš ï¸  GEMINI_API_KEY bulunamadÄ±! .env dosyasÄ±nÄ± kontrol edin.")
            print("   API key almak iÃ§in: https://aistudio.google.com/app/apikey")
            self.model = None
            return
        
        # Gemini yapÄ±landÄ±rmasÄ±
        genai.configure(api_key=api_key)
        
        # Model konfigÃ¼rasyonu (.env'den okunur)
        self.model_name = os.getenv("GEMINI_MODEL", "gemini-2.5-flash-lite")
        self.temperature = float(os.getenv("GEMINI_TEMPERATURE", "0.3"))
        self.max_tokens = int(os.getenv("GEMINI_MAX_TOKENS", "1024"))
        
        # Model instance (Native JSON Mode - 0.4.0+ gerektirir)
        self.model = genai.GenerativeModel(
            model_name=self.model_name,
            generation_config={
                "temperature": self.temperature,
                "max_output_tokens": self.max_tokens,
                "response_mime_type": "application/json",  # Native JSON mode
            }
        )
        
        # Rate Limit ayarlarÄ±
        self.rate_limit_max = int(os.getenv("GEMINI_RATE_LIMIT", "10"))
        self.rate_limit_window = 60  # 1 dakika (Sliding Window)
        
        # Cache ayarlarÄ±
        self.cache_ttl = int(os.getenv("GEMINI_CACHE_TTL", "300"))  # 5 dakika
        
        # Retry ayarlarÄ±
        self.max_retries = 4  # Toplam deneme sayÄ±sÄ±
        
        print(f"âœ… Gemini Analyzer (Redis + Tenacity) hazÄ±r")
        print(f"   Model: {self.model_name}")
        print(f"   Rate Limit: {self.rate_limit_max} req/min (Global)")
        print(f"   Cache TTL: {self.cache_ttl}s")
        print(f"   Retry: {self.max_retries} deneme (Exponential Backoff)")
    
    def _ensure_services(self) -> None:
        """
        Redis servislerinin baÅŸlatÄ±ldÄ±ÄŸÄ±ndan emin ol (Lazy Initialization)
        
        Neden lazy?
        - __init__ sÄ±rasÄ±nda Redis baÄŸlantÄ±sÄ± olmayabilir
        - Servisleri sadece gerÃ§ekten ihtiyaÃ§ duyulduÄŸunda baÅŸlat
        - Singleton pattern ile tekrar yaratmayÄ± Ã¶nle
        """
        if GeminiAnalyzerRedis._rate_limiter is None:
            redis_client = RedisManager.get_client()
            
            # Global rate limiter (tÃ¼m worker'lar paylaÅŸÄ±r)
            GeminiAnalyzerRedis._rate_limiter = RedisRateLimiter(
                redis_client=redis_client,
                key_prefix="gemini_ratelimit",
                max_requests=self.rate_limit_max,
                window_seconds=self.rate_limit_window
            )
            
            # Cache servisi
            GeminiAnalyzerRedis._cache_service = RedisCacheService(
                redis_client=redis_client,
                key_prefix="gemini_cache",
                default_ttl=self.cache_ttl
            )
            
            print("   ğŸ”„ Redis servisleri baÅŸlatÄ±ldÄ± (lazy init)")
    
    def _generate_cache_key(
        self,
        current: AggregatedMetrics,
        previous: Optional[AggregatedMetrics]
    ) -> str:
        """
        Metrikler iÃ§in deterministic cache key oluÅŸtur
        
        AynÄ± metrikler â†’ AynÄ± key â†’ Cache HIT
        
        Hassasiyet:
        - confidence: 2 ondalÄ±k
        - latency: 1 ondalÄ±k
        - time: dakika hassasiyeti
        """
        return RedisCacheService.generate_hash_key(
            total=current.total_predictions,
            confidence=round(current.average_confidence, 2),
            latency=round(current.average_inference_time_ms, 1),
            time=current.time_window_end.isoformat()[:16],  # Dakika hassasiyeti
            prev_total=previous.total_predictions if previous else 0
        )
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # RETRY KORUMASLI API Ã‡AÄRISI
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    @retry(
        stop=stop_after_attempt(4),  # Maksimum 4 deneme
        wait=wait_exponential(multiplier=1, min=1, max=10) + wait_random(0, 1),  # Exp backoff + jitter
        retry=retry_if_exception_type((
            ServiceUnavailable,      # 503 - GeÃ§ici, retry mantÄ±klÄ±
            DeadlineExceeded,        # Timeout - GeÃ§ici, retry mantÄ±klÄ±
            InternalServerError,     # 500 - Bazen geÃ§ici
            ConnectionError,         # Network - GeÃ§ici
            TimeoutError,            # Python timeout - GeÃ§ici
        )),
        # âŒ ResourceExhausted (429) burada YOK - Redis rate limit zaten var
        before_sleep=lambda retry_state: print(
            f"â³ Retry #{retry_state.attempt_number} - "
            f"Bekleniyor: {retry_state.next_action.sleep:.1f}s"
        )
    )
    async def _call_gemini_api(self, prompt: str) -> str:
        """
        Gemini API'ye istek at (Native Async + Retry korumalÄ±)
        
        google-generativeai 0.8.6+ sÃ¼rÃ¼mÃ¼nde generate_content_async()
        native async desteÄŸi saÄŸlar. Event loop'u bloklamaz.
        
        Retry edilecek hatalar:
        - 503 ServiceUnavailable
        - 500 InternalServerError
        - DeadlineExceeded (Timeout)
        - ConnectionError
        - TimeoutError
        
        Retry EDÄ°LMEYECEK hatalar:
        - 429 ResourceExhausted (Redis rate limit var)
        - 400 InvalidArgument (dÃ¼zeltilmesi gereken hata)
        - 401/403 Authentication (retry ile dÃ¼zelmez)
        
        Args:
            prompt: Gemini'ye gÃ¶nderilecek prompt
            
        Returns:
            str: Gemini'nin yanÄ±t metni
            
        Raises:
            RetryError: TÃ¼m denemeler baÅŸarÄ±sÄ±z olduysa
            ResourceExhausted: 429 hatasÄ± (retry yapÄ±lmadan)
            DiÄŸer Exception'lar: Retry dÄ±ÅŸÄ± hatalar
        """
        # Native async API Ã§aÄŸrÄ±sÄ± (google-generativeai 0.8.6+)
        response = await self.model.generate_content_async(prompt)
        return response.text
    
    async def _fetch_from_gemini(
        self,
        current_metrics: AggregatedMetrics,
        previous_metrics: Optional[AggregatedMetrics]
    ) -> GeminiAnalysisReport:
        """
        Gemini'den rapor al (Rate Limit + API + Parse)
        
        Bu factory fonksiyonu get_or_set_with_lock iÃ§inde Ã§aÄŸrÄ±lÄ±r.
        Lock iÃ§inde Ã§alÄ±ÅŸÄ±r, yani sadece 1 istek API'ye gider.
        
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘ FACTORY PATTERN                                                    â•‘
        â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
        â•‘ Bu method ÅŸunlarÄ± yapÄ±yor:                                        â•‘
        â•‘ 1. Rate limit kontrolÃ¼                                            â•‘
        â•‘ 2. Prompt oluÅŸturma                                               â•‘
        â•‘ 3. API Ã§aÄŸrÄ±sÄ± (Retry korumalÄ±)                                   â•‘
        â•‘ 4. Response parsing                                               â•‘
        â•‘                                                                    â•‘
        â•‘ Lock iÃ§inde Ã§aÄŸrÄ±ldÄ±ÄŸÄ± iÃ§in Cache Stampede olmaz!                 â•‘
        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        Args:
            current_metrics: GÃ¼ncel metrikler
            previous_metrics: KarÅŸÄ±laÅŸtÄ±rma iÃ§in Ã¶nceki metrikler
            
        Returns:
            GeminiAnalysisReport: Analiz raporu
            
        Raises:
            Exception: Rate limit aÅŸÄ±ldÄ±ysa veya API hatasÄ±
        """
        # Rate limit kontrolÃ¼
        allowed, remaining = await GeminiAnalyzerRedis._rate_limiter.is_allowed("global")
        
        if not allowed:
            reset_time = await GeminiAnalyzerRedis._rate_limiter.get_reset_time("global")
            raise Exception(
                f"Global rate limit aÅŸÄ±ldÄ± ({self.rate_limit_max}/dk). "
                f"Yeniden deneme: {reset_time} saniye"
            )
        
        print(f"ğŸš¦ Rate limit OK. Kalan: {remaining}")
        
        # Prompt oluÅŸtur
        prompt = self._build_analysis_prompt(current_metrics, previous_metrics)
        
        # API Ã§aÄŸrÄ±sÄ± (Retry korumalÄ±)
        response_text = await self._call_gemini_api(prompt)
        
        # Parse et
        report = self._parse_gemini_response(response_text, current_metrics)
        return report
    
    async def analyze_performance(
        self,
        current_metrics: AggregatedMetrics,
        previous_metrics: Optional[AggregatedMetrics] = None
    ) -> GeminiAnalysisReport:
        """
        Performans metriklerini Gemini ile analiz et
        (Cache Stampede korumalÄ± - Distributed Locking)
        
        Args:
            current_metrics: GÃ¼ncel metrikler
            previous_metrics: KarÅŸÄ±laÅŸtÄ±rma iÃ§in Ã¶nceki metrikler (opsiyonel)
            
        Returns:
            GeminiAnalysisReport: Analiz raporu
        
        AkÄ±ÅŸ (get_or_set_with_lock):
        1. Cache kontrolÃ¼ (HIT â†’ direkt dÃ¶ndÃ¼r)
        2. Lock edin (sadece 1 istek API'ye gider)
        3. Double-check cache (biri yazmÄ±ÅŸ olabilir)
        4. Factory Ã§alÄ±ÅŸtÄ±r (rate limit + API + parse)
        5. Cache'e kaydet
        6. Lock serbest bÄ±rak
        """
        if not self.model:
            return self._create_fallback_report(
                current_metrics,
                "Gemini API key yapÄ±landÄ±rÄ±lmamÄ±ÅŸ"
            )
        
        # Redis servislerini baÅŸlat (lazy)
        self._ensure_services()
        
        # Cache key oluÅŸtur
        cache_key = self._generate_cache_key(current_metrics, previous_metrics)
        
        # Factory fonksiyonu (lock iÃ§inde Ã§alÄ±ÅŸacak)
        async def factory():
            return await self._fetch_from_gemini(current_metrics, previous_metrics)
        
        try:
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # DISTRIBUTED LOCKING Ä°LE CACHE KONTROLÃœ
            # AynÄ± anda 50 istek gelse bile sadece 1'i API'ye gider!
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            report = await GeminiAnalyzerRedis._cache_service.get_or_set_with_lock(
                key=cache_key,
                model_class=GeminiAnalysisReport,
                factory=factory,
                ttl=self.cache_ttl,
                lock_timeout=30,
                lock_blocking_timeout=15.0
            )
            
            # Metrikleri gÃ¼ncelle (cache'te None olabilir)
            report.metrics_analyzed = current_metrics
            return report
            
        except RetryError as e:
            # TÃ¼m retry denemeleri baÅŸarÄ±sÄ±z oldu
            original_error = e.last_attempt.exception()
            error_msg = f"{self.max_retries} deneme baÅŸarÄ±sÄ±z: {type(original_error).__name__}"
            print(f"âŒ {error_msg}")
            return self._create_fallback_report(current_metrics, error_msg)
            
        except ResourceExhausted as e:
            # 429 hatasÄ± - Retry YAPILMADI (doÄŸru davranÄ±ÅŸ)
            error_msg = f"Google API kota aÅŸÄ±ldÄ± (429): {str(e)}"
            print(f"âŒ {error_msg}")
            return self._create_fallback_report(current_metrics, error_msg)
            
        except Exception as e:
            # DiÄŸer beklenmeyen hatalar (rate limit, parse error vb.)
            error_msg = str(e)
            print(f"âŒ Hata: {error_msg}")
            return self._create_fallback_report(current_metrics, error_msg)
    
    def _build_analysis_prompt(
        self,
        current: AggregatedMetrics,
        previous: Optional[AggregatedMetrics]
    ) -> str:
        """Gemini iÃ§in detaylÄ± analiz prompt'u oluÅŸtur"""
        
        prompt = f"""Sen bir Machine Learning Model Performance Analyst'sÄ±n.
Bir sentiment analiz modelinin performans metriklerini analiz etmelisin.

## GÃœNCEL METRÄ°KLER ({current.time_window_start} - {current.time_window_end})
- Toplam Tahmin SayÄ±sÄ±: {current.total_predictions}
- Ortalama GÃ¼ven Skoru: {current.average_confidence:.2f}
- Ortalama Gecikme: {current.average_inference_time_ms:.2f}ms
- P95 Gecikme: {current.p95_inference_time_ms:.2f}ms
- Min/Max Gecikme: {current.min_inference_time_ms:.2f}ms / {current.max_inference_time_ms:.2f}ms
- Sentiment DaÄŸÄ±lÄ±mÄ±: {dict(current.sentiment_distribution)}
- Durum: {current.status.value}
"""
        
        # Ã–nceki metriklerle karÅŸÄ±laÅŸtÄ±rma
        if previous and previous.total_predictions > 0:
            conf_change = ((current.average_confidence - previous.average_confidence) 
                          / previous.average_confidence * 100)
            
            # P95 Gecikme DeÄŸiÅŸimi (tail latency analizi iÃ§in daha profesyonel)
            # Fallback: p95 deÄŸeri None veya 0 ise hesaplama yapma
            if (previous.p95_inference_time_ms and previous.p95_inference_time_ms > 0 and
                current.p95_inference_time_ms and current.p95_inference_time_ms > 0):
                p95_latency_change = ((current.p95_inference_time_ms - previous.p95_inference_time_ms)
                                     / previous.p95_inference_time_ms * 100)
                p95_change_text = f"{p95_latency_change:+.1f}%"
            else:
                p95_change_text = "HesaplanamadÄ± (yetersiz veri)"
            
            prompt += f"""
## Ã–NCEKÄ° DÃ–NEM Ä°LE KARÅILAÅTIRMA
- GÃ¼ven Skoru DeÄŸiÅŸimi: {conf_change:+.1f}%
- P95 Gecikme DeÄŸiÅŸimi: {p95_change_text}
- Tahmin SayÄ±sÄ± FarkÄ±: {current.total_predictions - previous.total_predictions:+d}
"""
        
        prompt += """
## GÃ–REV
AÅŸaÄŸÄ±daki JSON formatÄ±nda bir analiz raporu oluÅŸtur:

```json
{
  "summary": "2-3 cÃ¼mlelik Ã¶zet",
  "identified_issues": [
    {
      "issue_type": "low_confidence | high_latency | data_drift",
      "severity": "low | medium | high | critical",
      "description": "Sorun aÃ§Ä±klamasÄ±"
    }
  ],
  "recommendations": [
    "Ã–neri 1",
    "Ã–neri 2"
  ],
  "root_cause_hypothesis": "KÃ¶k neden hakkÄ±nda hipotez",
  "confidence_score": 0.0-1.0 (bu analizine ne kadar gÃ¼veniyorsun)
}
```

Ã–NEMLÄ°:
- YanÄ±tÄ±nÄ± SADECE JSON olarak ver, baÅŸka metin ekleme
- identified_issues boÅŸ liste olabilir (sorun yoksa)
- TÃ¼rkÃ§e yaz
- Somut, actionable Ã¶neriler ver
- EÄŸer metrik sayÄ±sÄ± Ã§ok azsa (< 5), bunu belirt
"""
        
        return prompt
    
    def _parse_gemini_response(
        self,
        response_text: str,
        metrics: AggregatedMetrics
    ) -> GeminiAnalysisReport:
        """
        Gemini'nin JSON yanÄ±tÄ±nÄ± Pydantic ile parse et (Native JSON Mode)
        
        response_mime_type="application/json" sayesinde Gemini doÄŸrudan
        JSON dÃ¶ner, manuel string parsing'e gerek yok.
        """
        try:
            # Pydantic native JSON validation
            report = GeminiAnalysisReport.model_validate_json(response_text)
            
            # Metrik bilgisini manuel olarak ekle (Gemini bunu bilmiyor)
            report.metrics_analyzed = metrics
            
            return report
            
        except Exception as e:
            print(f"âš ï¸ Gemini yanÄ±tÄ± parse edilemedi: {e}")
            print(f"YanÄ±t: {response_text[:200]}...")
            return self._create_fallback_report(metrics, f"Parse hatasÄ±: {str(e)}")
    
    def _create_fallback_report(
        self,
        metrics: AggregatedMetrics,
        error_msg: str
    ) -> GeminiAnalysisReport:
        """
        Hata durumunda kural tabanlÄ± varsayÄ±lan rapor oluÅŸtur
        
        Tetiklenme durumlarÄ±:
        - Rate limit aÅŸÄ±ldÄ±
        - API hatasÄ± (tÃ¼m retry'lar baÅŸarÄ±sÄ±z)
        - Parse hatasÄ±
        - API key yok
        - 429 ResourceExhausted
        """
        issues = []
        recommendations = []
        
        # DÃ¼ÅŸÃ¼k gÃ¼ven kontrolÃ¼
        if metrics.average_confidence < 0.6:
            issues.append(PerformanceIssue(
                issue_type="low_confidence",
                severity="high",
                description=f"Ortalama gÃ¼ven skoru dÃ¼ÅŸÃ¼k: {metrics.average_confidence:.2f}"
            ))
            recommendations.append("Model yeniden eÄŸitimi dÃ¼ÅŸÃ¼nÃ¼n")
        
        # YÃ¼ksek gecikme kontrolÃ¼
        if metrics.average_inference_time_ms > 200:
            issues.append(PerformanceIssue(
                issue_type="high_latency",
                severity="medium",
                description=f"Ortalama gecikme yÃ¼ksek: {metrics.average_inference_time_ms:.2f}ms"
            ))
            recommendations.append("Sunucu kaynaklarÄ±nÄ± kontrol edin")
        
        # Yetersiz veri kontrolÃ¼
        if metrics.total_predictions < 5:
            summary = f"Yetersiz veri: Sadece {metrics.total_predictions} tahmin var. Daha fazla veri toplanmalÄ±."
        else:
            summary = f"Otomatik analiz: {len(issues)} sorun tespit edildi. (Hata: {error_msg})"
        
        return GeminiAnalysisReport(
            summary=summary,
            identified_issues=issues,
            recommendations=recommendations if recommendations else ["Daha fazla veri toplayÄ±n"],
            root_cause_hypothesis="Gemini API kullanÄ±lamadÄ±ÄŸÄ± iÃ§in kural tabanlÄ± analiz yapÄ±ldÄ±",
            confidence_score=0.3,
            metrics_analyzed=metrics
        )
    
    async def get_cache_stats(self) -> dict:
        """Cache istatistiklerini dÃ¶ndÃ¼r (debug/monitoring iÃ§in)"""
        self._ensure_services()
        return await GeminiAnalyzerRedis._cache_service.get_stats()
    
    async def get_rate_limit_status(self, identifier: str = "global") -> dict:
        """Rate limit durumunu dÃ¶ndÃ¼r"""
        self._ensure_services()
        _, remaining = await GeminiAnalyzerRedis._rate_limiter.is_allowed(identifier)
        reset_time = await GeminiAnalyzerRedis._rate_limiter.get_reset_time(identifier)
        
        return {
            "identifier": identifier,
            "remaining": remaining + 1,  # is_allowed bir hak kullandÄ±, geri ekle
            "max_requests": self.rate_limit_max,
            "reset_in_seconds": reset_time,
            "window_seconds": self.rate_limit_window
        }
    
    async def invalidate_cache(self, pattern: str = "*") -> int:
        """Cache'i temizle (threshold deÄŸiÅŸikliÄŸinde kullanÄ±lÄ±r)"""
        self._ensure_services()
        deleted = await GeminiAnalyzerRedis._cache_service.clear_prefix(pattern)
        print(f"ğŸ—‘ï¸ {deleted} cache entry silindi")
        return deleted


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BACKWARD COMPATIBILITY
# Eski kod `gemini_analyzer` kullanÄ±yorsa Ã§alÄ±ÅŸmaya devam etsin
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Global instance (yeni sÄ±nÄ±f)
gemini_analyzer = GeminiAnalyzerRedis()

# Legacy alias (eski import'lar iÃ§in)
GeminiAnalyzer = GeminiAnalyzerRedis
