"""
Gemini Analyzer Orchestrator

TÃ¼m bileÅŸenleri koordine eden ana orkestratÃ¶r.
Separation of Concerns: Sadece bileÅŸen koordinasyonu yapar.
"""
from typing import Optional

from tenacity import RetryError
from google.api_core.exceptions import ResourceExhausted

from schemas.metrics import AggregatedMetrics, GeminiAnalysisReport
from database.redis_connection import RedisManager
from core.redis_rate_limiter import RedisRateLimiter
from services.redis_cache import RedisCacheService

# Analyzer bileÅŸenleri
from services.analyzer.config import AnalyzerConfig
from services.analyzer.prompts import PromptBuilder
from services.analyzer.client import GeminiAPIClient
from services.analyzer.parser import ResponseParser, ParseError
from services.analyzer.fallback import FallbackEngine


class GeminiAnalyzerOrchestrator:
    """
    Gemini tabanlÄ± performans analizi iÃ§in ana orkestratÃ¶r
    
    Koordine eder:
    - Cache aramasÄ± (RedisCacheService)
    - Rate limiting (RedisRateLimiter)
    - Prompt oluÅŸturma (PromptBuilder)
    - API iletiÅŸimi (GeminiAPIClient)
    - YanÄ±t ayrÄ±ÅŸtÄ±rma (ResponseParser)
    - Fallback yÃ¶netimi (FallbackEngine)
    
    AkÄ±ÅŸ (get_or_set_with_lock):
    1. Cache kontrolÃ¼ (HIT â†’ direkt dÃ¶ndÃ¼r)
    2. Lock edin (sadece 1 istek API'ye gider)
    3. Double-check cache (biri yazmÄ±ÅŸ olabilir)
    4. Factory Ã§alÄ±ÅŸtÄ±r (rate limit + API + parse)
    5. Cache'e kaydet
    6. Lock serbest bÄ±rak
    """
    
    # Class-level services (singleton pattern)
    _rate_limiter: Optional[RedisRateLimiter] = None
    _cache_service: Optional[RedisCacheService] = None
    
    def __init__(self, config: Optional[AnalyzerConfig] = None):
        """
        OrkestratÃ¶rÃ¼ baÅŸlat
        
        Args:
            config: YapÄ±landÄ±rma (None ise env'den yÃ¼klenir)
        """
        # YapÄ±landÄ±rma
        self.config = config or AnalyzerConfig.from_env()
        
        # BileÅŸenleri baÅŸlat
        self.prompt_builder = PromptBuilder()
        self.api_client = GeminiAPIClient(self.config)
        self.parser = ResponseParser()
        self.fallback = FallbackEngine()
        
        # BaÅŸlangÄ±Ã§ mesajÄ±
        if self.api_client.is_configured:
            print(f"âœ… Gemini Analyzer Orchestrator hazÄ±r")
            print(f"   Rate Limit: {self.config.rate_limit_max} req/min (Global)")
            print(f"   Cache TTL: {self.config.cache_ttl}s")
    
    def _ensure_services(self) -> None:
        """
        Redis servislerinin baÅŸlatÄ±ldÄ±ÄŸÄ±ndan emin ol (Lazy Initialization)
        
        Neden lazy?
        - __init__ sÄ±rasÄ±nda Redis baÄŸlantÄ±sÄ± olmayabilir
        - Servisleri sadece gerÃ§ekten ihtiyaÃ§ duyulduÄŸunda baÅŸlat
        - Singleton pattern ile tekrar yaratmayÄ± Ã¶nle
        """
        if GeminiAnalyzerOrchestrator._rate_limiter is None:
            redis_client = RedisManager.get_client()
            
            # Global rate limiter (tÃ¼m worker'lar paylaÅŸÄ±r)
            GeminiAnalyzerOrchestrator._rate_limiter = RedisRateLimiter(
                redis_client=redis_client,
                key_prefix="gemini_ratelimit",
                max_requests=self.config.rate_limit_max,
                window_seconds=self.config.rate_limit_window
            )
            
            # Cache servisi
            GeminiAnalyzerOrchestrator._cache_service = RedisCacheService(
                redis_client=redis_client,
                key_prefix="gemini_cache",
                default_ttl=self.config.cache_ttl
            )
            
            print("   ğŸ”„ Redis servisleri baÅŸlatÄ±ldÄ± (lazy init)")
    
    def _generate_cache_key(
        self,
        current: AggregatedMetrics,
        previous: Optional[AggregatedMetrics]
    ) -> str:
        """
        Metrikler iÃ§in deterministic cache key oluÅŸtur
        
        AynÄ± metrikler â†’ AynÄ± key â†’ Cache HIT
        
        Hassasiyet:
        - confidence: 2 ondalÄ±k
        - latency: 1 ondalÄ±k
        - time: dakika hassasiyeti
        """
        return RedisCacheService.generate_hash_key(
            total=current.total_predictions,
            confidence=round(current.average_confidence, 2),
            latency=round(current.average_inference_time_ms, 1),
            time=current.time_window_end.isoformat()[:16],
            prev_total=previous.total_predictions if previous else 0
        )
    
    async def _fetch_from_gemini(
        self,
        current_metrics: AggregatedMetrics,
        previous_metrics: Optional[AggregatedMetrics]
    ) -> GeminiAnalysisReport:
        """
        Gemini'den rapor al (Rate Limit + API + Parse)
        
        Bu factory fonksiyonu get_or_set_with_lock iÃ§inde Ã§aÄŸrÄ±lÄ±r.
        Lock iÃ§inde Ã§alÄ±ÅŸÄ±r, yani sadece 1 istek API'ye gider.
        
        Args:
            current_metrics: GÃ¼ncel metrikler
            previous_metrics: KarÅŸÄ±laÅŸtÄ±rma iÃ§in Ã¶nceki metrikler
            
        Returns:
            GeminiAnalysisReport: Analiz raporu
            
        Raises:
            Exception: Rate limit aÅŸÄ±ldÄ±ysa veya API hatasÄ±
        """
        # Rate limit kontrolÃ¼
        allowed, remaining = await GeminiAnalyzerOrchestrator._rate_limiter.is_allowed("global")
        
        if not allowed:
            reset_time = await GeminiAnalyzerOrchestrator._rate_limiter.get_reset_time("global")
            raise Exception(
                f"Global rate limit aÅŸÄ±ldÄ± ({self.config.rate_limit_max}/dk). "
                f"Yeniden deneme: {reset_time} saniye"
            )
        
        print(f"ğŸš¦ Rate limit OK. Kalan: {remaining}")
        
        # Prompt oluÅŸtur
        prompt = self.prompt_builder.build_analysis_prompt(current_metrics, previous_metrics)
        
        # API Ã§aÄŸrÄ±sÄ± (Retry korumalÄ±)
        response_text = await self.api_client.generate(prompt)
        
        # Parse et (try_parse ile hata yÃ¶netimi)
        report, error = self.parser.try_parse(response_text, current_metrics)
        
        if error:
            raise ParseError(error)
        
        return report
    
    async def analyze_performance(
        self,
        current_metrics: AggregatedMetrics,
        previous_metrics: Optional[AggregatedMetrics] = None
    ) -> GeminiAnalysisReport:
        """
        Performans metriklerini Gemini ile analiz et
        (Cache Stampede korumalÄ± - Distributed Locking)
        
        Args:
            current_metrics: GÃ¼ncel metrikler
            previous_metrics: KarÅŸÄ±laÅŸtÄ±rma iÃ§in Ã¶nceki metrikler (opsiyonel)
            
        Returns:
            GeminiAnalysisReport: Analiz raporu
        """
        # API key kontrolÃ¼
        if not self.api_client.is_configured:
            return self.fallback.create_fallback_report(
                current_metrics,
                "Gemini API key yapÄ±landÄ±rÄ±lmamÄ±ÅŸ"
            )
        
        # Redis servislerini baÅŸlat (lazy)
        self._ensure_services()
        
        # Cache key oluÅŸtur
        cache_key = self._generate_cache_key(current_metrics, previous_metrics)
        
        # Factory fonksiyonu (lock iÃ§inde Ã§alÄ±ÅŸacak)
        async def factory():
            return await self._fetch_from_gemini(current_metrics, previous_metrics)
        
        try:
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # DISTRIBUTED LOCKING Ä°LE CACHE KONTROLÃœ
            # AynÄ± anda 50 istek gelse bile sadece 1'i API'ye gider!
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            report = await GeminiAnalyzerOrchestrator._cache_service.get_or_set_with_lock(
                key=cache_key,
                model_class=GeminiAnalysisReport,
                factory=factory,
                ttl=self.config.cache_ttl,
                lock_timeout=30,
                lock_blocking_timeout=15.0
            )
            
            # Metrikleri gÃ¼ncelle (cache'te None olabilir)
            report.metrics_analyzed = current_metrics
            return report
            
        except RetryError as e:
            # TÃ¼m retry denemeleri baÅŸarÄ±sÄ±z oldu
            original_error = e.last_attempt.exception()
            error_msg = f"{self.config.max_retries} deneme baÅŸarÄ±sÄ±z: {type(original_error).__name__}"
            print(f"âŒ {error_msg}")
            return self.fallback.create_fallback_report(current_metrics, error_msg)
            
        except ResourceExhausted as e:
            # 429 hatasÄ± - Retry YAPILMADI (doÄŸru davranÄ±ÅŸ)
            error_msg = f"Google API kota aÅŸÄ±ldÄ± (429): {str(e)}"
            print(f"âŒ {error_msg}")
            return self.fallback.create_fallback_report(current_metrics, error_msg)
            
        except ParseError as e:
            # Parse hatasÄ±
            error_msg = f"Parse hatasÄ±: {str(e)}"
            print(f"âŒ {error_msg}")
            return self.fallback.create_fallback_report(current_metrics, error_msg)
            
        except Exception as e:
            # DiÄŸer beklenmeyen hatalar (rate limit, network vb.)
            error_msg = str(e)
            print(f"âŒ Hata: {error_msg}")
            return self.fallback.create_fallback_report(current_metrics, error_msg)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MONITORING / DEBUG METODLARI
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def get_cache_stats(self) -> dict:
        """Cache istatistiklerini dÃ¶ndÃ¼r (debug/monitoring iÃ§in)"""
        self._ensure_services()
        return await GeminiAnalyzerOrchestrator._cache_service.get_stats()
    
    async def get_rate_limit_status(self, identifier: str = "global") -> dict:
        """Rate limit durumunu dÃ¶ndÃ¼r"""
        self._ensure_services()
        _, remaining = await GeminiAnalyzerOrchestrator._rate_limiter.is_allowed(identifier)
        reset_time = await GeminiAnalyzerOrchestrator._rate_limiter.get_reset_time(identifier)
        
        return {
            "identifier": identifier,
            "remaining": remaining + 1,  # is_allowed bir hak kullandÄ±, geri ekle
            "max_requests": self.config.rate_limit_max,
            "reset_in_seconds": reset_time,
            "window_seconds": self.config.rate_limit_window
        }
    
    async def invalidate_cache(self, pattern: str = "*") -> int:
        """Cache'i temizle (threshold deÄŸiÅŸikliÄŸinde kullanÄ±lÄ±r)"""
        self._ensure_services()
        deleted = await GeminiAnalyzerOrchestrator._cache_service.clear_prefix(pattern)
        print(f"ğŸ—‘ï¸ {deleted} cache entry silindi")
        return deleted
